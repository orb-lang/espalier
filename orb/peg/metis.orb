* Metis

   The system responsible for building, analyzing, and manipulating input into
the Vav combinator.


** Design

We receive a Grammar in a dialect of PEG, the Vav combinator takes it and
combines it in various ways, this is linked to a Qopf via Dji, producing a
Peh, something which takes a string and outputs a result.

Analysis and various rule transformations are performed by this module.


*** Synth Nodes

This is officially a pattern since we do the same thing with Scry.

Here it is particularly important because we expect to do a lot of rewriting
of terms based on underlying strings which will not be identical.


** M

The 'machinery' for this sort of pattern will end up in cluster eventually.

Here we set it all up by hand for the second time.


**** imports

#!lua
local Node = require "espalier:espalier/node"
local Grammar = require "espalier:espalier/grammar"
local core = require "qor:core" -- #todo another qor
local cluster = require "cluster:cluster"
local table = core.table
local Set = core.set
local Deque = require "deque:deque"
local insert, remove, concat = assert(table.insert),
                               assert(table.remove),
                               assert(table.concat)
local s = require "status:status" ()
#/lua


***** normalize

  Causes any =-= in a name to become =_=, allowing us to treat them as
interchangeable.  This is my crank compromise between ordinary string
matching and creations such as Nim's symbol equivalence and unified call
syntax.

#!lua
local gsub = assert(string.gsub)

local function normalize(str)
   return gsub(str, "%-", "%_")
end
#/lua


*** Qualia

We'll fill this in as we go deeper.

#!lua
local Q = {}
#/lua


*** Metabuilder

  This pattern goes into its own module eventually/soon/as part of what I'm
doing right now.

Lets us automatically build a metatable for class =something= by indexing
=Metas.something=.

I'm tempted to do something automagic with =Metas.Something= but like, not,
right now.


**** Twig

This is clearly part of what a generator does automatically /but/

#!lua
local Twig = Node :inherit()
#/lua


#!lua
local function __index(metabuild, key)
   metabuild[key] = Twig :inherit(key)
   return metabuild[key]
end
#/lua

#!lua
local M = setmetatable({Twig}, {__index = __index})
#/lua


*** Rules

This is where we set up the information graph for a given Vav.


*** Scry Synth Copypasta

This really is one distinct thing but yeah.


**** builder(_new, synth, node, i)

#!lua
local new, Syndex, SynM = cluster.order()

local function builder(_new, synth, node, i)
   synth.up = i
   synth.o = node.first
   synth.node = node
   synth.line, synth.col = node:linePos()
   -- this is just for reading purposes, remove
   synth.class = _new.class
   return synth
end
cluster.construct(new, builder)

#/lua


***** Synth lens

#!lua
local suppress = Set {
   'parent',
   --'line',
   'o',
   'col',
   'up',
   'node',
}
local _lens = { hide_key = suppress,
                depth = 6 }
local Syn_repr = require "repr:lens" (_lens)

SynM.__repr = Syn_repr
#/lua


*** Synth Equality

We say a synth is equal to another if:

- A leaf node has the same class and string value

- A branch node the same class and has all children equal by this rule

Note that we have an opportunity to provide memoized equality here by pointing
between branch nodes already proven equal, either manually as 'cut' points or
just as part of the equality operation.

#!lua
function SynM.__eq(syn1, syn2)
   -- different classes or unequal lengths always neq
   if (syn1.class ~= syn2.class)
      or (#syn1 ~= #syn2) then
         return false
   end
   -- two tokens?
   if (#syn1 == 0) and (#syn2 == 0) then
      -- same length?
      if syn1:stride() ~= syn2:stride() then
         return false
      end
      local str1, str2 = syn1.node.str, syn2.node.str
      local o1, o2 = syn1.o, syn2.o
      local same = true
      for i = 0, syn1:stride() - 1 do
         local b1, b2 = byte(str1, i + o1), byte(str2, i + o2)
         if b1 ~= b2 then
            same = false
            break
         end
      end
      return same
   end
   -- two leaves with the same number of children
   local same = true
   for i = 1, #syn1 do
      if not syn1[i] == syn2[i] then
         same = false
         break
      end
   end
   return same
end
#/lua


*** Synth Metamaker

We do this a couple of ways...

First we inherit from =new= if we haven't seen the class aka node =.id=:

#!lua
local newSes, metaSes =  {}, {}

local function makeGenus(class)
   local _new, Class, Class_M = cluster.genus(new)
   cluster.extendbuilder(_new, true)
   newSes[class] = _new
   metaSes[class] = Class
   Class.class = class
   for quality, set in pairs(Q) do
      if set[class] then
         Class[quality] = true
      end
   end
   return _new, Class, Class_M -- we ignore the metatable. until we dont'.
end

local function newSynth(node, i)
   local class = node.id
   local _new, Class = newSes[class]
   if not _new then
      _new, Class = makeGenus(class)
   end
   return _new(node, i)
end
#/lua

Second we have a metamaker, letting us say =Syn.class.whatever= and get the
correct index table (Cassette).

#!lua
local function Syn_index(Syn, class)
   local meta, _ = metaSes[class]
   if not meta then
      _, meta = makeGenus(class)
      Syn[class] = meta
   end
   return meta
end

local Syn = setmetatable({Syndex}, {__index = Syn_index })
#/lua


*** Base Synth methods

The goal with clades is to allow these sorts of methods to be composable
without any visitor BS, once again we're handrolling here.

#!lua
local walk = require "gadget:walk"
local filter, reduce = assert(walk.filter), assert(walk.reduce)
local classfilter = {}

local function filterer(class)
   local F = classfilter[class]
   if not F then
      classfilter[class] = function(node)
                        return node.class == class
                     end
      F = classfilter[class]
   end
   return F
end

local curry = assert(core.fn.curry)

local function setfilter(set, node)
   return set[node.class]
end

function _filter(synth, pred)
   if type(pred) == 'string' then
      return filter(synth, filterer(pred))
   elseif type(pred) == 'table' then
      -- presume a Set
      return filter(synth, curry(pred))
   else
      return filter(synth, pred)
   end
end
Syndex.filter = _filter

function Syndex.take(synth, pred)
   for syn in _filter(synth, pred) do
      return syn
   end
end

function Syndex.reduce(synth, pred)
   if type(pred) == 'string' then
      return reduce(synth, filterer(pred))
   else
      return reduce(synth, pred)
   end
end
#/lua


#!lua
function Syndex.span(synth)
   return synth.node:span()
end
#/lua


#!lua
function Syndex.stride(synth)
   return node.last - node.first + 1
end
#/lua


#!lua
function Syndex.nameOf(synth)
   return synth.name or synth.class
end
#/lua

While these may be useful, they are as yet unused:

#!lua
function Syndex.left(syn)
   return syn.parent[syn.up + 1]
end

function Syndex.right(syn)
   return syn.parent[syn.up - 1]
end
#/lua

Might actually want 'left' and 'right' for something a little more useful?


**** 'Syndex' base for analysis and synthesis

Is just pass, probably these should be promoted to errors because synthesis
and analysis should be exhaustive... maybe? This is my best guess.

#!lua
Syndex.synthesize = cluster.ur.pass
Syndex.analyze = cluster.ur.pass
#/lua


**** _synth(node)

Let's get this out of the way real quick.

#!lua
local function _synth(node, parent_synth, i)
   local synth = newSynth(node, i)
   synth.parent = parent_synth or synth
   for i, twig in ipairs(node) do
      synth[i] = _synth(twig, synth, i)
   end
   return synth
end
#/lua

#!lua
function M.rules.synthesize(rules)
   rules.start = rules :take 'rule'
   rules.synth = _synth(rules)
   return rules.synth
end
#/lua


** Data gathering

We're just going to be greedy and get our hands on any static relationships
we can, and use them later.

Broken up into several chunks for clarity.


*** rules:collectRules()

Time for a big ol' info dump!  May as well grab All The Formats and see where
we get w. it.

- returns a map of the following:

  - nameSet:  The set of every name in normalized token form.

  - ruleMap:  A map from the rule name (token) to the rule itself.

  - ruleCalls:  A map of the token for a rule to an array of the name of each
                rule it calls. This overwrites duplicate rules, which don't
                interest me very much except as something we lint and prune.

  - ruleSet:  A set containing the name of all defined rules.

  - dupe:  An array of any rule synth which has been duplicated later, this
           reflects the semantics of lpeg which overwrites a =V"rule"=
           definition if it sees a second one.

  - surplus:  An array of any rule which isn't referenced by name on the
              right hand side.

  - missing:  Any rule referenced by name which isn't defined in the grammar.



#!lua
function Syn.rules.collectRules(rules)
   local nameSet = Set {}
   for name in rules :filter 'name' do
      local token = normalize(name:span())
      nameSet[token] = true
   end
   local dupe, surplus = {}, {}
   local ruleMap = {}   -- token => node
   local ruleCalls = {} -- token => {name*}
   local ruleSet = Set {}   -- #{rule_name}
   for rule in rules :filter 'rule' do
      local token = normalize(rule :take 'rule_name' :span())
      ruleSet[token] = true
      if ruleMap[token] then
         -- lpeg uses the *last* rule defined so we do likewise
         insert(dupe, ruleMap[token])
      end
      ruleMap[token] = rule
      if not nameSet[token] then
         -- while it is valid to refer to the top rule, it is not noteworthy
         -- when a grammar does not.
         -- rules[1] is kind of sloppy but we're just going in the order of
         -- inspiration...
         if not (rule == rules[1]) then
            insert(surplus, rule)
         end
      end
      -- build call graph
      local calls = {}
      ruleCalls[token] = calls
      for name in rule :filter 'name' do
         local tok = normalize(name:span())
         insert(calls, tok)
      end
   end
   local missing = {}
   for name in pairs(nameSet) do
      if not ruleMap[name] then
         insert(missing, name)
      end
   end
   -- #improve should dupe, surplus, missing be sets?
   return { nameSet = nameSet,
            ruleMap = ruleMap,
            ruleCalls = ruleCalls,
            ruleSet = ruleSet,
            dupe = dupe,
            surplus = surplus,
            missing = missing, }
end
#/lua


**** partition(ruleCalls)

This partitions the rules into regular and recursive.

'Regular' here is not 100% identical to 'regular language' due to references
and lookahead, but it's suitably close.


#!lua
local function partition(ruleCalls, callSet)
   local base_rules = Set()
   for name, calls in pairs(ruleCalls) do
      if #calls == 0 then
         base_rules[name] = true
         callSet[name] = nil
      end
   end

   local rule_order = {base_rules}
   local all_rules, next_rules = base_rules, Set()
   local TRIP_AT = 512
   local relaxing, trip = true, 1
   while relaxing do
      trip = trip + 1
      for name, calls in pairs(callSet) do
         local based = true
         for call in pairs(calls) do
            if not all_rules[call] then
               based = false
            end
         end
         if based then
            next_rules[name] = true
            callSet[name] = nil
         end
      end
      if #next_rules == 0 then
         relaxing = false
      else
         insert(rule_order, next_rules)
         all_rules = all_rules + next_rules
         next_rules = Set()
      end

      if trip > TRIP_AT then
         relaxing = false
         error "512 attempts to relax rule order, something is off"
      end
   end

   return rule_order, callSet
end
#/lua

#!lua
local clone1 = assert(table.clone1)

local function _callSet(ruleCalls)
   local callSet = {}
   for name, calls in pairs(ruleCalls) do
      callSet[name] = Set(clone1(calls))
   end
   return callSet
end
#/lua


**** graphCalls(rules)

  Now that we've obtained all the terminal rules, we can use a bit of set
addition and a queue to obtain the full rule set seen by any other given
rule.

#!lua
local function setFor(tab)
   return Set(clone1(tab))
end

local function graphCalls(rules)
   local collection = assert(rules.collection)
   local ruleCalls, ruleMap = assert(collection.ruleCalls),
                               assert(collection.ruleMap)
   local regulars = assert(collection.regulars)

   -- go through each layer and build the full dependency tree for regular
   -- rules
   local regSets = {}
   -- first set of rules have no named subrules
   local depSet = regulars[1]
   for name in pairs(depSet) do
      ruleMap[name].final = true
      regSets[name] = Set {}
   end
   -- second tier has only the already-summoned direct calls
   depSet = regulars[2]
   for name in pairs(depSet) do
      regSets[name] = setFor(ruleCalls[name])
   end
   -- the rest is set arithmetic
   for i = 3, #regulars do
      depSet = regulars[i]
      for name in pairs(depSet) do
         local callSet = setFor(ruleCalls[name])
         for _, called in ipairs(ruleCalls[name]) do
            callSet = callSet + regSets[called]
         end
         regSets[name] = callSet
      end
   end
   --  the regulars collected, we turn to the recursives and roll 'em up
   local recursive = assert(collection.recursive)
   local recurSets = {}
   -- make a full recurrence graph for one set
   local function oneGraph(name, callSet)
      local recurSet = callSet + {}
      -- start with known subsets
      for elem in pairs(callSet) do
         local subSet = regSets[elem] or recurSets[elem]
         if subSet then
            recurSet = recurSet + subSet
         end
      end
      -- run a queue until we're out of names
      local shuttle = Deque()
      for elem in pairs(recurSet) do
         shuttle:push(elem)
      end
      for elem in shuttle:popAll() do
         for _, name in ipairs(ruleCalls[elem]) do
            if not recurSet[name] then
               shuttle:push(name)
               recurSet[name] = true
            end
         end
      end

      recurSets[name] = recurSet
   end

   for name, callSet in pairs(recursive) do
      oneGraph(name, callSet)
   end
   local allCalls = clone1(regSets)
   for name, set in pairs(recurSets) do
      allCalls[name] = set
   end
   return regSets, recurSets, allCalls
end
#/lua

#!lua
function Syn.rules.analyze(rules)
   local collection = rules:collectRules()
   rules.collection = collection
   local regulars, recursive = partition(collection.ruleCalls, rules:callSet())
   local ruleMap = assert(collection.ruleMap)
   collection.regulars, collection.recursive = regulars, recursive
   for name in pairs(recursive) do
      ruleMap[name].recursive = true
   end
   local regSets, recurSets, calls = graphCalls(rules)
   collection.calls = calls
   -- sometimes we want to know what a given rule /can't/ see
   local ruleSet = collection.ruleSet
   local blind = {}
   for name, callSet in pairs(calls) do
      blind[name] = ruleSet - callSet
   end
   collection.blind = blind
   -- do we need the intermediates for anything?
   return blind, calls
end
#/lua

#!lua
function Syn.rules.callSet(rules)
   local collection = rules.collection or rules:collectRules()
   return _callSet(collection.ruleCalls)
end
#/lua


** Analysis




*** What is a 'rule'

One of the first things we do is 'reify' the rule structure by assigning
names to any rule which doesn't have one.  So a rule is any pattern which
recognizes some area of a string in some context.

The product of Dji may or may not be in a position to work with phantom or
suppressed rules, it may in fact ignore rule structure completely if it is,
say, a validator.


*** Two lenses

In fact there are two useful ways to massage the given structure, thanks to
the use of hidden rules.

One of these is 'ghost' rules, where every pattern is treated as a rule
whether named or not, and unrolling all the hidden rules to give an engine
which only has rule names which can show up in the final parse.

I know that the ghost approach will be useful, I'll ignore the other one for
now.


**** lock rules

A rule is a lock if, once the containing rule has succeeded against this rule,
the container must either succeed the rest of the rule or fail: specifically
it cannot backtrack past a lock rule and succeed.

Example being ="= for a string and so on, some of them are easy to spot but I
do expect that rules like =("k" b "y") / ("K" B "Y")= will be more
interesting, this is really two rules tried one after the other and inlined,
the rule itself doesn't have a lock but rather two.  Noting that it has two
locks is easier than reducing the *lock* partof the rule to ={Kk}=.


**** gate rules

A rule is a gate if it must be passed for the containing rule to succeed.


*** rules:constrain()

#!lua
function Syn.rules.constrain(rules)
   -- now what lol
   -- well, we have the 'tiers' for the regulars, so we can start with zero
   -- dep and accumulate wisdom.
   local collection = assert(rules.collection)
   local ruleMap, regulars = collection.ruleMap, collection.regulars
   local workSet = regulars[1]
   for elem in pairs(workSet) do
      local rule = ruleMap[elem]
   end
end
#/lua


#!lua
return M
#/lua
