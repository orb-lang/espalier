* Mem


The tools of higher combination.

#!lua
local Clade, Node = use ("cluster:clade", "espalier:peg/node")
#/lua


*** [#Todo] Refactor

This is in pretty good shape, I can add some sessions which will stabilize the
key operations, I think.


**** [#Todo] Use :G()

We have this awkward "collection" we pass around, I've added a method which
causes Nodes to have a table =.g=, which is the tree-global state.

I was originally going to keep =.v= on it, but that's kind of dodgy.  It adds
complexity, and the algorithm based on finding root and adjusting everything
only has bad behavior for very deep trees.

It's a good fit for a lot of existing Node patterns, honestly.


**** [#Todo] Vector the Mixin

This isn't inherently useful for Mem, but it's critical for composability that
the codegen mixin be stored in the vector by the name of the method.


**** Clade Extension

#!lua
local function postindex(tab, field)
   tab[field].tag = field
   return tab[field]
end

local contract = {postindex = postindex, seed_fn = true}

local MemClade = Clade(Node, contract):extend(contract)
local Mem = MemClade.tape
local Basis = Mem[1]
local Mem_M = MemClade.meta[1]

Basis.v = 1
#/lua

This is where we crack our knuckles and start porting.


**** imports

#!lua
local core = use "qor:core"
local table = core.table
local Set = core.set
local Deque = use "deque:deque"
local insert, remove, concat = assert(table.insert),
                               assert(table.remove),
                               assert(table.concat)
local s = use "status:status" ()
s.verbose = false
#/lua


***** normalize

  Causes any =-= in a name to become =_=, allowing us to treat them as
interchangeable.  This is my crank compromise between ordinary string
matching and creations such as Nim's symbol equivalence and unified call
syntax.

#!lua
local gsub = assert(string.gsub)

local function normalize(str)
   return gsub(str, "%-", "%_")
end
#/lua


*** Qualia

Our categories which cut across rule identities.

#!lua
local Q = MemClade.quality
#/lua


**** Q.nofail

Any rule type which matches the empty string.

Note there is one type of repeat rule =name%0..5= which is also optional but
we must detect this (we do not as yet).

#!lua
Q.nofail = Set {'zero_plus', 'optional'}
#/lua


**** Q.predicate

A match which will never advance the cursor, but which can succeed or fail.

#!lua
Q.predicate = Set {'and', 'not'}
#/lua


**** Q.failsucceeds

A rule which succeeds by failing, aka =not=.

There is a reason to have a category of one, which is that this condition
propagates beyond its definition during rule constraint.

#!lua
Q.failsucceeds = Set {'not'}
#/lua


**** Q.nullable

A rule which can match without advancing the cursor.

#!lua
Q.nullable = Q.predicate + Q.nofail
#/lua


**** Q.compound

#!lua
Q.compound = Set {'cat', 'alt'}
#/lua


**** Q.terminal

Rules which produce a definite amount of cursor movement in and of themselves.

#!lua
Q.terminal = Set {'literal', 'set', 'range', 'number'}
#/lua


**** Q.unbounded

Rules which can consume arbitrary amounts of input inherently.

This doesn't account for recursive analysis: = A <- "a" A= type grammars can
be identified, and will be, but not by class.

#!lua
Q.unbounded = Set { 'zero_plus', 'one_plus' }
#/lua

Which we can also represent inside-out as traits pertaining to a class:

#!lua
local Prop = {}

for trait, classSet in pairs(Q) do
   for class in pairs(classSet) do
      Prop[class] = Prop[class] or {}
      insert(Prop[class], trait)
   end
end
for class, array in pairs(Prop) do
   Prop[class] = Set(array)
end
#/lua


***** Other Trait Sets

  These are used in various places in the module, and it's useful to have them
all in one spot.

Clades should have a way to check the validity of this sort of construct.

We use these to massage rules into shape:

#!lua
local SpecialSnowflake = Set {'set', 'range', 'name',
                               'number', 'literal', 'rule_name'}
local Hoist = Set {'element', 'alt', 'cat'}
#/lua

#!lua
local Prefix = Set {'and', 'not', 'to_match'}
local Suffix = Set {'zero_plus', 'one_plus', 'optional', 'repeat'}
local Backref = Set {'backref'}

local Surrounding = Prefix + Suffix + Backref
#/lua


****** Copy Traits

  These are traits such that, if a rule has them, the reference/name must also
have them.

#!lua
local CopyTrait = Set {'locked', 'predicate', 'nullable', 'null', 'terminal',
                   'unbounded', 'compound', 'failsucceeds', 'nofail',
                   'recursive', 'self_recursive'}
#/lua


****** Locks

These are forms which can acquire and pass locks.

#!lua
local Locks = Set {'cat', 'alt', 'group', 'element', 'name'}
#/lua


**** __repr

Some copypasta while we figure out a better way.

#!lua
local tablib = require "repr:tablib"
local yieldName = assert(tablib.yieldName)
local yieldReprs = assert(tablib.yieldReprs)
local yieldToken = assert(tablib.yieldToken)
local concat = assert(table.concat)
local floor = math.floor
local sort = table.sort
local sub = string.sub

local function blurb(node, w, c)
   if not (node.o and node.O and node.str) then return end
   local span = node:span()
   local width = w.width
   if #span > width - 12 then
      local half = floor(width / 4)
      local head, tail = sub(span, 1, half), sub(span, -half -1, -1)
      span = c.string(head) .. c.stresc(" ⋯ ") .. c.string(tail)
      span = span
                :gsub("\n+", c.greyscale("◼︎") .. c.string())
                :gsub("[ ]+", c.greyscale("␣") .. c.string())
   else
      span = c.string(span)
   end

   local V = c.number("v" .. node.v)
   local skew = c.bold(tostring(node.O - node.o))
   local first = V..skew.." "..c.metatable(node.tag)..": ".." "..span.."\n"
   local second = {}
   for trait in pairs(CopyTrait) do
      if node[trait] then
         insert(second, c["true"](trait))
      end
   end
   sort(second)
   if #second == 0 then
      return first
   else
      return first .. concat(second, "::")
   end
end
#/lua

#!lua
local Lens = use "repr:lens"
local Set = core.set

local suppress = Set {
   'parent',
   'up',
   'str',
   'o', 'O', 'v',
   'stride',
   'references',
   'modified',
   ---[[DBG]] --[=[
   'constrained_by_rule',
   'constrained_by_fixed_point',
   'compound',
   --]=]
} + CopyTrait

local lens = { hide_key = suppress,
               blurb = blurb,
               depth = math.huge }
Mem_M.__repr = Lens(lens)
#/lua


** Mem Basis

Methods in common to the entire Phyle.

Other basis methods are presented along with their specified versions.


***** Basis:parentRule()

Returns the parent rule of the part.

#!lua
function Basis.parentRule(mem)
   if mem.tag == 'rule' then return nil, 'this is a rule' end
   if mem.tag == 'grammar' then return nil, 'this is a grammar' end
   local parent = mem.parent
   repeat
      if parent.tag == 'rule' then
         return parent
      else
         parent = parent.parent
      end
   until parent:isRoot()

   return nil, 'mistakes were made (new tree structure?)'
end
#/lua


***** Basis:nameOfRule()

Returns the name of the enclosing rule.

#!lua
function Basis.nameOfRule(mem)
   local rule, why = mem:parentRule()
   if not rule then
      return nil, why
   end
   return rule.token
end
#/lua


**** Basis:nameFor()

Gives us something to call the Node.

#!lua
function Basis.nameOf(mem)
   return mem.token or mem.tag
end
#/lua


*** Synthesis

Here we decorate particular Nodes with useful representations and
contextual information.


#Todo these can happen at recognition time with a custom extension of seeds.


**** extraSpecial(node)

  Decorates [[certain rules][@other-trait-sets]] with useful additional
information.

#!lua
local function extraSpecial(node)
   local c = node.tag
   if c == 'range' then
      node.from_char, node.to_char = node[1]:span(), node[2]:span()
      -- we'll use this in codegen #todo
      node.ASCII = #node.from_char == 1 and #node.to_char == 1
   elseif c == 'set' then
      node.value = node:span()
   elseif c == 'name' or c == 'rule_name' then
      node.token = normalize(node:span())
   else
      node.token = node:span()
   end
end
#/lua

#!lua
local analyzeElement;

local function synthesize(node)
   for _, twig in ipairs(node) do
      synthesize(twig)
   end
   if SpecialSnowflake[node.tag] then
      extraSpecial(node)
   end
   -- elements
   if node.tag == 'element' then
      analyzeElement(node)
   elseif node.tag == 'rule' then
      node.token = normalize(node :take 'rule_name' :span())
   end
   return node
end
#/lua


**** analyzeElement(elem)

The parser change puts all the modifiers on the element, which is useful.

Since we hoist a few redundant classes, any element which remains is modified
in some fashion, what we do here is promote that information onto the
element, and copy it to the component part, such that we no longer need to
consider those synth nodes.

We then dispose of the surroundings, except for back references.

#!lua
function analyzeElement(elem)
   local prefixed, backrefed  = Prefix[elem[1].tag],
                                Backref[elem[#elem].tag]
   local suffixed;
   if backrefed then
      suffixed = Suffix[elem[#elem-1].tag]
   else
      suffixed = Suffix[elem[#elem].tag]
   end
   local modifier = { prefix = false,
                      suffix = false,
                      backref = false, }

   local part

   if prefixed then
      modifier.prefix = elem[1]
      part = elem[2]
   else
      part = elem[1]
   end

   if backrefed and suffixed then
      modifier.backref = elem[#elem]
      modifier.suffix  = elem[#elem - 1]
   elseif suffixed then
      modifier.suffix = elem[#elem]
   elseif backrefed then
      modifier.backref = elem[#elem]
   end
   assert(part and (not Surrounding[part.tag]),
          "weirdness encountered analyzing element")
   for _, mod in pairs(modifier) do
      if mod then
         elem.modified = true
         elem[mod.tag] = true
         for trait in pairs(CopyTrait) do
            elem[trait] = mod[trait]
         end
      end
   end
   -- strip now-extraneous information
   for i = 1, #elem do
      elem[i] = nil
   end
   elem[1] = part
   if backrefed then
      elem[2] = modifier.backref
   end
end
#/lua

#!lua
local function toHoist(node)
   return Hoist[node.tag]
          and #node == 1
          and (not node.modified)
end
#/lua

We need to first collect the 'hoistable' Nodes, then hoist them, due to the
sort of problems we would otherwise get when modifying the structure of
something while iterating over it.

#!lua
function Mem.grammar.synthesize(grammar)
   grammar.start = grammar :take 'rule'
   synthesize(grammar)
   local shuttle = Deque()
   for twig in grammar :walk() do
      if toHoist(twig) then
         shuttle:push(twig)
      end
   end
   for twig in shuttle:popAll() do
      twig:hoist()
   end
   grammar:G().is_synthesized = true
   return grammar
end
#/lua


*** Helpful Methods

  These are various affordances for working with a grammar, ones which aren't
directly tied to the phases.


**** grammar:rule 'name'

The main advance here is being able to refer to a rule in kebab case.

#!lua
function Mem.grammar.rule(grammar, name)
   local g = grammar:G()
   if not g.ruleMap then
      grammar:collectRules()
   end
   return g.ruleMap[normalize(name)]
end
#/lua


*** Analysis

  This is the stage where we establish the primary structural characteristics
of the grammar.

This is many variations on who-calls what, which we establish with:


**** grammar:collectRules()

  Builds up a large collection of relational information, while decorating
rules and names with tokens representing their normalized value.

This uses the grammar's general table =.g= to accumulate the following.

- g:

  - nameSet:  The set of every name in normalized token form.

  - nameMap:  The tokens of nameSet mapped to an array of all right hand side
              references in the grammar.

  - ruleMap:  A map from the rule name (token) to the synthesized rule.

  - ruleCalls:  A map of the token for a rule to an array of the name of each
                rule it calls. This overwrites duplicate rules, which don't
                interest me very much except as something we lint and prune.

  - ruleSet:  A set containing the name of all defined rules.

  - dupe:  An array of any rule synth which has been duplicated later.  The
           tools follow the semantics of lpeg, which overwrites a =V"rule"=
           definition if it sees a second one.

  - surplus:  An array of any rule which isn't referenced by name on the
              right hand side.

  - missing:  Any rule referenced by name which isn't defined in the grammar.

#Todo this step is expensive, and I should figure out why with some profiling,
   see if we can either do without some of it or reduce some big O.


#!lua
local sort, nonempty, getset = table.sort,
                               assert(table.nonempty),
                               assert(table.getset)

function Mem.grammar.collectRules(grammar)
   if not grammar:G().is_synthesized then
      grammar:synthesize()
   end
   -- our containers:
   local nameSet, nameMap = Set {}, {} -- #{token*}, token => {name*}
   local dupe, surplus, missing = {}, {}, {} -- {rule*}, {rule*}, {token*}
   local ruleMap = {}   -- token => synth
   local ruleCalls = {} -- token => {name*}
   local ruleSet = Set {}   -- #{rule_name}

   for name in grammar :filter 'name' do
      local token = normalize(name:span())
      name.token = token
      nameSet[token] = true
      local refs = getset(nameMap, token)
      insert(refs, name)
   end

   local start_rule = grammar :take 'rule'

   for rule in grammar :filter 'rule' do
      local token = assert(rule.token)
      rule.references = nameMap[token]
      ruleSet[token] = true
      if ruleMap[token] then
         -- lpeg uses the *last* rule defined so we do likewise
         ruleMap[token].duplicate = true
         insert(dupe, ruleMap[token])
      end
      ruleMap[token] = rule
      if not nameSet[token] then
         --  While it is valid to refer to the top rule, it isn't noteworthy
         --  when a grammar does not.
         --  Rules which are not findable from the start rule aren't part of
         --  the grammar, and are therefore surplus
         if rule ~= start_rule then
            rule.surplus = true
            insert(surplus, rule)
         end
      end
      -- build call graph
      local calls = {}
      ruleCalls[token] = calls
      for name in rule :filter 'name' do
         local tok = normalize(name:span())
         insert(calls, tok)
      end
   end

   -- account for missing rules (referenced but not defined)
   for name in pairs(nameSet) do
      if not ruleMap[name] then
         insert(missing, name)
      end
   end
   sort(missing)

   -- add our collections to the general table
   local g = grammar:G()
   g.start = start_rule
   g.nameSet   = nameSet
   g.nameMap   = nameMap
   g.ruleMap   = ruleMap
   g.ruleCalls = ruleCalls
   g.ruleSet   = ruleSet
   g.dupe      = nonempty(dupe)
   g.surplus   = nonempty(surplus)
   g.missing   = nonempty(missing)
end
#/lua


***** partition(ruleCalls)

This partitions the rules into regular and recursive.

'Regular' here is not 100% identical to 'regular language' due to references
and lookahead, but it's suitably close.

#improve Set arithmetic is clean to write and easy to reason about, but using
it as an accumulator i.e. ==set = set + newSet== is generally wasteful and
we can drop some allocation pressure by iteration and setting to true.  This
would call for profiling, and is only worth considering because programmatic
generation of fairly complex grammar is on the horizon.

#!lua
local function partition(ruleCalls, callSet)
   local base_rules = Set()
   for name, calls in pairs(ruleCalls) do
      if #calls == 0 then
         base_rules[name] = true
         callSet[name] = nil
      end
   end

   local rule_order = {base_rules}
   local all_rules, next_rules = base_rules, Set()
   local TRIP_AT = 512
   local relaxing, trip = true, 1
   while relaxing do
      trip = trip + 1
      for name, calls in pairs(callSet) do
         local based = true
         for call in pairs(calls) do
            if not all_rules[call] then
               based = false
            end
         end
         if based then
            next_rules[name] = true
            callSet[name] = nil
         end
      end
      if #next_rules == 0 then
         relaxing = false
      else
         insert(rule_order, next_rules)
         all_rules = all_rules + next_rules
         next_rules = Set()
      end

      if trip > TRIP_AT then
         relaxing = false
         error "512 attempts to relax rule order, something is off"
      end
   end

   return rule_order, callSet
end
#/lua


**** Mem.grammar.callSet(grammar)

This makes Sets non-destructively out of arrays of rule names, which might not
have to be non-destructive, but comes with no disadvantages at this point.

#!lua
local clone1 = assert(table.clone1)

local function _callSet(ruleCalls)
   local callSet = {}
   for name, calls in pairs(ruleCalls) do
      callSet[name] = Set(clone1(calls))
   end
   return callSet
end
#/lua

#!lua
function Mem.grammar.callSet(grammar)
   return _callSet(grammar:G().ruleCalls)
end
#/lua


***** graphCalls(grammar)

  Now that we've obtained all the terminal rules, we can use more set
addition and a queue to obtain the full rule set seen by any other given
rule.

This returns a map of names to a Set of every rule which can be visited from
that rule name, followed by the regular and recursive halves, which we do not
currently collect.

#!lua
local function setFor(tab)
   return Set(clone1(tab))
end

local function graphCalls(grammar)
   local collection = assert(grammar:G())
   local ruleCalls, ruleMap = assert(collection.ruleCalls),
                               assert(collection.ruleMap)
   local regulars = assert(collection.regulars)

   -- go through each layer and build the full dependency tree for regular
   -- rules
   local regSets = {}

   -- first set of rules have no named subrules
   -- which we call 'final'
   local depSet = regulars[1]
   for name in pairs(depSet) do
      ---[[DBG]] ruleMap[name].final = true
      regSets[name] = Set {}
   end
   -- second tier has only the already-summoned direct calls
   depSet = regulars[2] or {}
   for name in pairs(depSet) do
      regSets[name] = setFor(ruleCalls[name])
   end
   -- the rest is set arithmetic
   for i = 3, #regulars do
      depSet = regulars[i]
      for name in pairs(depSet) do
         local callSet = setFor(ruleCalls[name])
         for _, called in ipairs(ruleCalls[name]) do
            callSet = callSet + regSets[called]
         end
         regSets[name] = callSet
      end
   end

   --  the regulars collected, we turn to the recursives and roll 'em up
   local recursive = assert(collection.recursive)
   local recurSets = {}

   -- make a full recurrence graph for one set
   local function oneGraph(name, callSet)
      local recurSet = callSet + {}
      -- start with known subsets
      for elem in pairs(callSet) do
         local subSet = regSets[elem] or recurSets[elem]
         if subSet then
            recurSet = recurSet + subSet
         end
      end
      -- run a queue until we're out of names
      local shuttle = Deque()
      for elem in pairs(recurSet) do
         shuttle:push(elem)
      end
      for elem in shuttle:popAll() do
         for _, name in ipairs(ruleCalls[elem] or {}) do
            if not recurSet[name] then
               shuttle:push(name)
               recurSet[name] = true
            end
         end
      end

      recurSets[name] = recurSet
   end

   for name, callSet in pairs(recursive) do
      oneGraph(name, callSet)
   end
   local allCalls = clone1(regSets)
   for name, set in pairs(recurSets) do
      allCalls[name] = set
   end
   return allCalls, regSets, recurSets
end
#/lua


***** trimRecursive(recursive)

#!lua
local function trimRecursive(recursive, ruleMap)
   for rule, callset in pairs(recursive) do
      for elem in pairs(callset) do
         if (not ruleMap[elem])
            or (not ruleMap[elem].recursive) then
            callset[elem] = nil
         end
      end
   end

   return recursive
end
#/lua


*** grammar:analyze()

Pulls together the caller-callee relationships.

#!lua
-- local partition, trimRecursive, graphCalls;

function Mem.grammar.analyze(grammar)
   local g = grammar:G()
   if not g.is_synthesized then
      grammar:synthesize()
   end
   if not g.ruleMap then
      grammar:collectRules()
   end

   local regulars, recursive = partition(g.ruleCalls, grammar:callSet())
   local ruleMap = assert(g.ruleMap)
   for name in pairs(recursive) do
      ruleMap[name].recursive = true
   end
   g.regulars, g.recursive = regulars, trimRecursive(recursive, ruleMap)
   g.calls = graphCalls(grammar)
   if g.missing then
      grammar:makeDummies()
   end

   local any, why = grammar:anomalies()
   if not any then
      g.is_analyzed = true
   end
   return any, why
end
#/lua


** Anomalous Grammars

A grammar is anomalous if it has missing, duplicate, or surplus rules.

Duplicate rules are a simple error, since the only semantic of a duplicate
rule is to overwrite the earlier with the latter, so we have no further
action to take in the moments before the mistake is corrected by the user.

Missing rules we can account for by building placeholders, which we do.

Surplus rules are an interesting case, because there is a coherent kind of
surplus rule or rules: an alternate grammar built partially or wholly from
rules referenced from the start rule of the grammar.

The intention of the Vav framework is that it will be tractable to assemble
this sort of rule from parts, and this is more clear than embedding several
grammars into one.

But it's a coherent action to take on surplus rules, the semantic is clear
enough, and we'll consider doing it.


*** grammar:anomalies()

If everything is in order, returns =nil, message=, otherwise, the
less-than-perfect aspects of the grammar as-is.

#!lua
function Mem.grammar.anomalies(grammar)
   local coll = grammar:G()
   if not coll then return nil, "collectRules first" end
   if not (coll.missing or coll.surplus or coll.dupe) then
      return nil, "no anomalies detected"
   else
      return { missing = coll.missing,
               surplus = coll.surplus,
               dupe   = coll.dupe }
   end
end
#/lua


** Peh Methods

  Various functions to produce a Peh: a string in PEG format specifying a
grammar.


*** grammar:makeDummies()

Does nothing if =.missing= is empty, otherwise makes dummies of missing rules.

The dummy rule just matches the string of the missing rule name, giving us a
reasonable placeholder to allow testing of portions of a grammar before
filling in the remaining clauses.

#!lua
local find, gsub = string.find, string.gsub

local function dumbRule(name, pad, patt)
   return   name .. "  <-  " .. pad .. patt .. pad .. "\n"
end

function Mem.grammar.makeDummies(grammar)
   local g = grammar:G()
   if not g.ruleMap then
      g:analyze()
   end
   local missing = g.missing
   if (not missing) or #missing == 0 then
      return nil, 'no rules are missing'
   end
   local dummy_str, pad = {"\n\n"}, " "
   if g.ruleMap['_'] then
      pad = " _ "
   end
   for _, name in ipairs(missing) do
      local patt;
      if find(name, "_") then
         patt = '"' .. (gsub(name, "_", '" {-_} "') .. '"')
      else
         patt = '"' .. name .. '"'
      end
      insert(dummy_str, dumbRule(name, pad, patt))
   end
   g.dummy_rules = concat(dummy_str)
end
#/lua


*** grammar:pehFor 'rule'

  Returns the concatenated peg string to recognize a single rule, which will
include rules referenced recursively.

#Todo  The call sets are supposed to be complete for a given rule, so the
       use of a shuttle and =added= check here shouldn't be necessary.

#!lua
function Mem.grammar.pehFor(grammar, rule)
   if not grammar:G().ruleMap then
      grammar:collectRules()
   end
   local g = grammar.g
   local calls, ruleMap, missing = g.calls,
                                   g.ruleMap,
                                   g.missing
   local phrase =  {}
   insert(phrase, ruleMap[rule]:span())

   local shuttle = Deque()
   shuttle :push(calls[rule])
   local added = {rule = true}
   for call_set in shuttle :popAll() do
      for rule_name in pairs(call_set) do
         if not added[rule_name] then
            added[rule_name] = true
            if ruleMap[rule_name] then
               insert(phrase, ruleMap[rule_name]:span())
               shuttle :push(calls[rule_name])
            end
         end
      end
   end

   return concat(phrase, "\n\n")
end
#/lua


** Constrain

  The constraint phase of the algorithm uses the mappings established in
analysis to provide insight into the compound and recursive structure of the
grammar.

=:constrain= requires that the grammar be ordinary, not anomalous: we don't
bother doing fancy things with under or over-specified grammars.

#Todo  The =to-match= rule generates correct code, but hasn't been
       meaningfully integrated with the constraint system.  Nor have backrefs.

       =to-match= is syntax sugar, and we probably want to unsugar it.
       Backrefs have meaningful semantics we need to be careful with, but in
       principle it's a lock and gate with unusual semantics.


**** Propagation

Grammars are recursive, and allow an arbitrary amount of indirection, so our
only hope of completing this constraint process is to reach a fixed point,
where calling =:constrain= on any of the Nodes will have no further effect.

We've already determined the call 'tiers' for non-recursive rules, and we
can begin by constraining the rules we call final: those with no references
at all.

Each regular tier from that point is constrained by constraining the rule,
and propagating the traits to each reference.

This leaves recursion, direct or otherwise. We repeatedly constrain rules, and
propagate any changes we've recovered, until every name we see doesn't change
when we copy the traits over.  At which point the constraints are complete,
and we can do things with them.


***** The Shuttle

We push all the rules onto a Deque, in an order which means we'll constrain
the regular rules the first time through.  We tag in-flight rules so that
names, in particular, don't end up there twice.


*** Base :constrain

Is a placeholder while we chase down things.

#!lua
function Basis.constrain(basis, coll)
   for i, elem in ipairs(basis) do
      elem:constrain(coll)
   end
   basis.base_constraint_rule = true
   basis.constrained = true
   local g = basis:G()
   insert(getset(g, 'unconstrained'), basis.tag)
end
#/lua


**** queueUp(shuttle, node)

This keeps us from pushing a node which is already on queue, in particular we
can see a rule many times before we check it again, and this keeps it on the
queue at-most-once.

#!lua
local function queueUp(shuttle, node)
   if node.on then return end
   node.on = true
   shuttle:push(node)
end
#/lua


**** Basis:enqueue()

#!lua
function Basis.enqueue(basis)
   if basis.on then return end
   local g = basis:G()
   basis.seen = basis.seen and basis.seen + 1 or 1
   g.count = g.count + 1
   if g.count > 2^16 then
      for term in g.shuttle:popAll() do
         term.on = nil
         term.stuck_in_limbo = true
      end
      error "shuttle is wandering, infinite loop likely"
   end
   g.shuttle:push(basis)
end
#/lua


*** grammar:constrain()

Performs the post-analysis constraint satisfaction.


**** BAIL_AT

The queue can potentially run for a long time in a grammar with many rules, so
we set this reasonably high.

In principle we should be able to get a good guess based on the complexity
we've already collected but.  But.

#!lua
local BAIL_AT = 16384
#/lua

#!lua
local mutate = assert(table.mutate)

function Mem.grammar.constrain(grammar)
   local g = grammar:G()
   local coll = g
   if not g.ruleMap then
      grammar:analyze()
   end
   if grammar:anomalies() then
      return nil, "can't constrain imperfect grammar (yet)", grammar:anomalies()
   end

   local regulars, ruleMap = g.regulars, g.ruleMap
   local shuttle = Deque()
   g.shuttle = shuttle
   g.count = 0
   for _, tier in ipairs(regulars) do
      for name in pairs(tier) do
         ruleMap[name]:enqueue()
      end
   end
   for name in pairs(g.recursive) do
      ruleMap[name]:enqueue()
   end
   local bail = 0
   for node in shuttle:popAll() do
      if type(node) == 'table' then
         node.on = nil
         bail = bail + 1
         node:constrain()
         if bail > BAIL_AT then
            grammar.had_to_bail = true
            grammar.no_constraint = {}
            for rule in grammar :filter 'rule' do
               if not rule.constrained then
                  grammar.no_constraint[rule.token] = rule
               end
            end
            break
         end
      else
         -- something got on the queue?
         local ts = require "repr:repr".ts_color
         local bare = require "valiant:replkit".bare
         error((
            "weird result %s from queue %s")
                :format(tostring(node), ts(bare(shuttle))))
      end
   end
   grammar.nodes_seen = bail
   grammar.had_to_bail = not not grammar.had_to_bail
end
#/lua


*** rule:constrain(coll)

Constrains an individual rule.

#!lua
function Mem.rule.constrain(rule)
   local rhs = assert(rule :take 'rhs')
   assert(#rhs == 1, "bad arity on RHS")
   local body = rhs[1]
   body:constrain()
   if body.constrained then
      rule.constrained = true
      rhs.constrained = true
      if Q.terminal[body.tag] then
         rule.locked = true
      end
   else
      rule:enqueue()
   end
   for trait in pairs(CopyTrait) do
      if body[trait] then
        rule[trait] = body[trait]
      end
   end
   rule:propagateConstraints()
end
#/lua


*** rule:propagateConstraints(coll)

Sends all changes to the rule to each name.

If this produces any changes, queues up the parent rule of the referenced name
for another go-around, and if not, marks it constrained.


**** copyTraits(rule, ref): changed: b

Copies over traits, returning =true= if any of the copied traits has changed
the state of =name=.

#!lua
local function copyTraits(rule, ref)
   local changed = false
   for trait in pairs(CopyTrait) do
      if rule[trait] then
         local differs = ref[trait] ~= rule[trait]
         changed = changed or differs
         ref[trait] = rule[trait]
      end
   end

   return changed
end
#/lua

#!lua
function Mem.rule.propagateConstraints(rule)
   if rule.references then -- could be the start rule
      for _, ref in ipairs(rule.references) do
         local changed = copyTraits(rule, ref)
         if changed then
            ref:parentRule():enqueue()
         else
            ref.constrained = true
         end
      end
   end
end
#/lua


*** terminals

#!lua
local function termConstrain(terminal)
   terminal.constrained = true
end

for class in pairs(Q.terminal) do
   Mem[class].constrain = termConstrain
end
#/lua


*** Compound constraints: cat, alt

Cat and alt are where all the fancy happens, we need to look for 'locked' cat
rules: those which, once started, will fail if they don't reach a specific
end rule and succeed.


**** cat:constrain()

This is the most complex part of the constraint algorithm.

We're looking for locks, dams, and gates.

A lock is a pattern which, once passed, will fail the rule if the match
doesn't reach the gate pattern.

A dam is any intermediate rule with the same property.

#!lua
function Mem.cat.constrain(cat)
   local locked;
   local gate;
   local idx;
   local again;
   local terminal = true
   local nofail = true
   local nullable = true
   for i, sub in ipairs(cat) do
      -- reset our conditions because we routinely do this several times
      sub.lock, sub.dam, sub.gate, sub.gate_lock = nil, nil, nil, nil

      --[[DBG]] sub.back_gate = nil
      sub:constrain()

      if not sub.constrained then
         again = true
      end

      if sub.predicate or sub.terminal then
         idx = i
         if gate then
            gate.gate = nil
         end
         if locked and gate.lock and sub.failsucceeds then
            sub.lock = true
         end
         gate = sub
         if (not locked) then
            sub.lock = true
            locked = true
         elseif not (sub.lock or sub.nullable) then
            sub.dam = true
         elseif sub.failsucceeds then
            sub.dam = true
         end
      end

      if sub.terminal then
         terminal = true
      end

      if sub.unbounded then
         cat.unbounded = true
      end
      nofail = nofail and sub.nofail
      nullable = nullable and sub.nullable
   end

   cat.terminal = (terminal and not nullable) or nil
   cat.nofail   = nofail or nil
   cat.nullable = nullable or nil
   cat.constrained = not again
   if (not again) and gate then
      gate.dam = nil
      if gate.lock then
         gate.gate_lock = true
      else
         gate.gate = true
         -- look for other unfailable /terminal/ rules
         -- at-most-one unbounded gate at the end
         if not gate.unbounded then
            for i = idx-1, 1, -1 do
               local sub = cat[i]
               if (not sub.terminal) or sub.lock or sub.unbounded then
                  break
               end
               --[[DBG]] sub.back_gate = true
               sub.gate = true
               sub.dam = nil
            end
         end
      end
   elseif not again then
      locked = false -- right? lock but no gate = not locked
   end

   if locked then
      cat.locked = true
   end
end
#/lua


**** alt:constrain()

#!lua
function Mem.alt.constrain(alt)
   local constrained = true
   -- can be true for any choice
   local nofail, nullable = nil, nil
   -- must be true for all choices
   local locked, predicate, terminal = true, true, true

   for _, sub in ipairs(alt) do
      sub:constrain()
      if not sub.constrained then
         constrained = false
      end
      if sub.unbounded then
         alt.unbounded = true
      end
      terminal = terminal and sub.terminal
      locked = locked and sub.locked
      predicate = predicate and sub.predicate

      nofail = nofail or sub.nofail
      nullable = nullable or sub.nullable
   end
   alt.nofail      = nofail
   alt.nullable    = nullable
   alt.terminal    = terminal or nil
   alt.locked      = locked or nil
   alt.predicate   = predicate or nil
   alt.constrained = constrained
end
#/lua


*** element:constrain(coll)

All remaining =element= nodes carry some modifier, so we copy over the traits
of the element proper, then remove the =terminal= trait if the modifiers
prevent it.

A terminal rule produces an excursion down the string, no exceptions: this is
never true of predicates and sometimes untrue of optionals of every stripe.

#!lua
function Mem.element.constrain(element)
   -- ??
   local again
   for _, sub in ipairs(element) do
      sub:constrain()
      if sub.constrained then
         -- copy then reconcile
         for trait in pairs(CopyTrait) do
            element[trait] = element[trait] or sub[trait]
         end
         if element.nullable or element.predicate then
            element.terminal = nil
         end
      else
         again = true
      end
   end
   element.constrained = not again
end
#/lua


**** group:constrain()

  Groups should always have one kid, so we just lift the qualities when we're
constrained.

I think we could hoist groups, but just tag the child element as 'grouped' so
that codegen does the right thing.  It's not clear that we want to.

#!lua
function Mem.group.constrain(group)
   assert(#group == 1, "group has too many kids (or no kid?)")
   group[1]:constrain()
   if group[1].constrained then
      for trait in pairs(CopyTrait) do
         group[trait] = group[trait] or group[1][trait]
      end
      group.constrained = true
   end
end
#/lua


*** name:constrain(coll)

  Simply checks if the rule it references has already constrained it, if not,
puts that rule back on the shuttle for another try.

#!lua
function Mem.name.constrain(name)
   if not name.constrained then
      name:ruleOf():enqueue()
   end
end
#/lua

#!lua
function Mem.name.ruleOf(name)
   return name:G().ruleMap[name.token]
end
#/lua


***** Catching optional repeats

If the lower bound on a repeat is zero, it's optional.

#Todo this doesn't propagate the properties of the rule being repeated.  I'm
not sure I actually use repeat rules, so I need some tests to get it right.

The flip side being, like =to-match=, I don't actually /need/ it yet...

#!lua
function Mem.repeated.constrain(repeated)
   local range = repeated :take 'integer_range'
   if not range then return end
   local start = tonumber(range[1])
   if start == 0 then
      repeated.nofail = true
      repeated.nullable = true
   end
   repeated.needs_work = true -- just a little reminder
   repeated.constrained = true
end
#/lua


** Deduce

  The deduction phase is where we take our constraints and use them to build a
complete view of the parser.


*** Next

We need to analyze =alt= groupings for "lock fails rule".

This gets intricate!  We have to compare literals, sets, ranges, with
repetition and lookahead.

I think the trick is simple: we reduce sets and ranges to the literals, and
test anything else against them.

Yeah. Just... make the pattern on the spot, try it out.

If we even have to, because repetitions nest in each other, or don't.

While we're in there, we're looking for choice shadowing: if a rule will
always consume a rule after it in the choice order, that's a bug.

With lock fails rule, we can the unhappy paths out of the grammar.

Then we can start putting together the fragment parser, the error-recovering
parser with =lpeglable.T=, and all that other fun stuff.  I expect it will
help with the madcap combinator scheme I have in mind for re-parsing trees...


**** Lock Promotion

This is where we bundle up the full lock reference for each =cat=, attaching
it to the rule, then propagate that up to any =alt= that uses the rule.

This lets us compare the rules, to see which ones are eliminated, and to
determine whether a later choice is shadowed by an earlier choice.


*** grammar:deduce()

Exactly like with constraints, we pop off a shuttle until everything has
found its home.

#!lua
function Mem.grammar.deduce(grammar)
   local g = grammar:G()
   g.constrain_count = g.count
   g.count = 0
   if not (g.start and g.start.constrained) then
      grammar:constrain()
   end
   if not g.start.constrained then
      return nil, "grammar can't be constrained"
   end
   for rule in grammar :filter 'rule' do
      rule:enqueue()
   end
   for rule in g.shuttle :popAll() do
      rule:acquireLock()
   end
end
#/lua


**** rule:acquireLock()

#!lua
function Mem.rule.acquireLock(rule)
   if rule.the_lock then
      rule:propagateLock()
      return rule.the_lock
   end
   if rule.locked then
      local body = rule :body()
      if Locks[body.tag] then
         local the_lock = body:acquireLock()
         if the_lock then
            rule.the_lock = the_lock
         else
            rule:enqueue()
         end
      elseif body.terminal then
         rule.the_lock = body
      else
         rule.body_does_not_lock = true
      end

      rule:propagateLock()
      return rule.the_lock
   end
end
#/lua


**** rule:body(), :bodyTag()

#!lua
function Mem.rule.body(rule)
   return rule :take 'rhs' [1]
end
function Mem.rule.bodyTag(rule)
   return rule:body().tag
end
#/lua


**** rule:propagateLock()

Sets ==name['prop'] = value== for all references to the rule.

If value isn't given, it's =rule['prop']=.

#!lua
function Mem.rule.propagateLock(rule)
   local the_lock = rule.the_lock
   if not the_lock then
      return
   end

   if rule.references then
      for _, ref in ipairs(rule.references) do
         local has_lock = ref.the_lock
         ref.the_lock = the_lock
         if not has_lock then
            ref:parentRule():enqueue()
         end
      end
   end
end
#/lua


**** name:acquireLock()

#!lua
function Mem.name.acquireLock(name)
   if name.the_lock then
      return name.the_lock
   end
   if name.locked then
      name:ruleOf():enqueue()
   end
end
#/lua


**** cat:acquireLock()

The main complication for =cat= is that the lock is not necessarily the first
element, nor is it necessarily one element.

#!lua
function Mem.cat.acquireLock(cat)
   if not cat.locked then
      return false
   end
   if cat.the_lock then
      return cat.the_lock
   end
   cat.on = true
   local again = false
   local the_lock = { the_lock = true }
   local seen_lock = false
   for _, sub in ipairs(cat) do
      if seen_lock and (not sub.lock) then
         if Locks[sub.tag] then
            sub:acquireLock()
         end
      elseif sub.lock then
         if sub.the_lock then
            insert(the_lock, sub.the_lock)
            seen_lock = true
         elseif Q.terminal[sub.tag] then
            insert(the_lock, sub)
            seen_lock = true
         elseif Locks[sub.tag] then
            seen_lock = true
            local a_lock = sub:acquireLock()
            if a_lock then
               insert(the_lock, a_lock)
            else
               again = true
            end
         end
      end
   end
   if again or #the_lock == 0 then
      cat:parentRule():enqueue()
      return false
   else
      cat.on = false
      cat.the_lock = the_lock
      return the_lock
   end
end
#/lua


**** alt:acquireLock()

Alts don't have a lock, so much as a lock collection.

Here we create and gather that collection, the more complex analysis is
performed after.

#!lua
function Mem.alt.acquireLock(alt)
   if not alt.locked then
      return "don't lock unlocked"
   end
   if alt.the_lock then
      alt.stuck, alt.stuck_on = nil, nil
      return alt.the_lock
   end
   local the_lock = { the_lock = true, alt_lock = true}
   local again = false
   for _, choice in ipairs(alt) do
      if choice.the_lock then
         insert(the_lock, choice.the_lock)
      elseif Q.terminal[choice.tag] then
         insert(the_lock, choice)
      elseif Locks[choice.tag] then
         local a_lock = choice:acquireLock()
         if a_lock then
            insert(the_lock, a_lock)
         else
            alt.stuck = true
            alt.stuck_on = {_, choice.tag}
            again = true
         end
      end
   end
   if again then
      alt:parentRule():enqueue()
      return false
   else
      alt.stuck = nil
      alt.stuck_on = nil
      alt.the_lock = the_lock
      return the_lock
   end
end
#/lua



*** element:acquireLock()

#!lua
function Mem.element.acquireLock(element)
   if element.the_lock then
      return element.the_lock
   end
   local the_lock;

   local body = element[1]
   if Locks[body.tag] and body.locked then
      the_lock = body:acquireLock()
   elseif body.terminal then
      the_lock = body
   end
   if the_lock then
      element.the_lock = the_lock
      return the_lock
   else
      element:enqueue()
      return false
   end
end
#/lua


**** group:acquireLock()

#!lua
function Mem.group.acquireLock(group)
   if group.the_lock then
      return group.the_lock
   end
   if group.lock then
      return group
   end
   group.on = true
   local the_lock;
   local elem = group[1]
   if Locks[elem.tag] and elem.locked then
      the_lock = elem:acquireLock()
   elseif elem.terminal then
      the_lock = elem
   end
   if the_lock then
      group.on = false
      group.the_lock = the_lock
      return the_lock
   else
      group:enqueue()
      return false
   end
end
#/lua



**** Interlude

  So the above code is producing plausible results, I'd be surprised if it was
correct in detail but I can squash bugs as I find them.

It's just not the correct algorithm, not by a long shot.  We're just trying
rules over and over until their references happen to have something useful
to say, which we only ever see from the top.

One possibility would be to have a coroutine per rule, and /yield/ instead of
just shrugging when a name isn't ready and loading up the queue.  Eventually
we have to find a rule which is either basic, or has only a self-reference in
addition to some terminal.

At that point, we can /reply/ to every name waiting on that rule, with a
resume, and whatever compound it was constraining can continue until it finds
another name that it needs to wait for.

The other possibility is to stay single-threaded, but register an interest.

So if we find a reference which is waiting on a rule, we register the
reference with the rule, marking all the parents up to the parent rule as
pending.  When a rule completes, it propagates to all the names, when we've
done all the rules once, we're done.

For the algorithm I just banged out, the coroutine approach is closer to what
I already have, and lock propagation doesn't have the issue with cycles which
trait propagation does.

It's also a better algorithm for building the call graph, and otherwise
collecting the rule information, so, let's start there.

#!lua
local nest = core.thread.nest 'Mem'

local Create, Yield, Resume = assert(nest.create),
                              assert(nest.yield),
                              assert(nest.resume)
local status = coroutine.status
#/lua


**** Dequer()

Do you like my owl?

#!lua
local function Dequer()
   local function index(deq, key)
      deq[key] = Deque()
      return deq[key]
   end
   return setmetatable({}, { __index = index })
end
#/lua


***** waiting(co)

#!lua
local function waiting(co)
   return status(co) == 'suspended'
end
#/lua


#!lua
function Mem.grammar.wander(grammar)
   local g = grammar:G()
   local thread, ruleMap, dupe_thread, having, wanting = {},{},{},{},{}
   local await = Dequer()
   g.thread, g.await, g.having, g.wanting = thread, await, having, wanting
   local coMap = {}
   local haveQ = Deque()
   -- we want to move a rule back every time we await it, to capture as many
   -- awaits as possible before resuming any of them
   local function push(tok)
      haveQ:offqueue(tok)
      haveQ:push(tok)
   end
   g.haveQ = haveQ

   for rule in grammar :filter 'rule' do
      local token = rule.token
      if thread[token] then
         -- surplus rule
         getset(dupe_thread, token)
         insert(dupe_thread[token], thread[token])
      end
      local co = Create(rule.wander)
      thread[token]= co
      coMap[co] = token
      ruleMap[token] = rule
   end
   for rule_name, co in pairs(thread) do
      local ok, wants = Resume(co, ruleMap[rule_name])
      assert(ok, wants)
      if waiting(co) then
         wanting[rule_name] = wants
         await[wants.await]:push(co)
      else
         wanting[rule_name] = nil
         having[rule_name] = wants
         push(rule_name)
      end
   end
   -- at this point, all rules are either back, or awaiting returns.
   -- we just have to drive it forward until all the coroutines return.
   for rule_name in haveQ:popAll() do
      local wants = having[rule_name]
      local awaiting = await[rule_name]
      for co in awaiting:popAll() do
         if not type(co) == 'thread' then
            error ("offended by element of type " .. type(co))
         end
         wanting[coMap[co]] = nil
         local ok, wants = Resume(co, wants)
         assert(ok, wants)
         if waiting(co) then
            await[wants.await]:push(co)
            if having[wants.await] then
               push(wants.await)
            else
               wanting[coMap[co]] = wants
            end
         else
            having[coMap[co]] = wants
            push(coMap[co])
         end
      end
   end
   -- this gets every regular rule... now what.
   -- step one: trim
   for name, Q in pairs(await) do
      if #Q == 0 then
         await[name] = nil
      end
      -- these are recursive
      -- what comes after can probably live here
   end
   -- so now we need to send what we have to everthing which is still
   -- awaiting, but keep track of them.
   for name, Q in pairs(await) do
      -- no sense in a bunch of :offqueue we know we don't need
      haveQ:push(name)
   end ---[[
   for name in haveQ:popAll() do
      local calls;
      if having[name] then
         calls = having[name]
      else
         local awaits = assert(wanting[name])
         calls = assert(wanting[awaits.await].calls)
      end
      for co in await[name]:popAll() do
         local ok, wants = Resume(co, calls)
         assert(ok, wants)
         if waiting(co) then
            await[wants.await]:push(co)
            push(wants.await)
         else
            push(name)
         end
      end
   end --]]

   setmetatable(await, nil) -- something is indexing it in helm :/

   return true
end
#/lua


#!lua
function Mem.rule.wander(rule)
   local callSet = {}
   for name in rule :filter 'name' do
      local response = Yield {await = name.token, calls = callSet}
      for k, v in pairs(response) do
         callSet[k] = v
      end
      callSet[name.token] = true
   end
   rule.calls = Set(callSet)
   return rule.calls
end
#/lua

































#== ::note::
***** Rule Ordering and Grouping

We want this for formatting and a bunch of other good reasons.

The algorithm:

Start rule is its own group.

First block is everything mentioned in the start rule, in order.

Second block is everything mentioned in the first block, and so on.

This is for a *normal form*, not necessarily how we pretty-print, which can be
more intelligent about putting things like whitespace at the end where they
belong.
#/==



*** Codegen Mixin

#Todo This should be a Clade vector.

#!lua
local codegen = require "espalier:peg/codegen"

for class, mixin in pairs(codegen) do
   for trait, method in pairs(mixin) do
      Mem[class][trait] = method
   end
end
#/lua


#!lua
return MemClade
#/lua

